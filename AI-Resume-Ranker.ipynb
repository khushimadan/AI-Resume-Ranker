{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a401a9c-923d-4d43-9f38-4707ecb61847",
   "metadata": {},
   "source": [
    "# AI RESUME RANKER\n",
    "How does it work?\n",
    "* User uploads a Resume (pdf/docx format) and Job Description (text)\n",
    "* Preprocess both the texts (cleaning, tokenization etc)\n",
    "* Convert both texts into embeddings (first using basic TF-IDF then using SBERT maybe even fine tuning it)\n",
    "* Compute Similarity Score using Cosine Similarity\n",
    "* Show result -\n",
    "  > * High Score (80-100%) -> Resume is a great match!\n",
    "  > * Medium Score (50-79%) -> Resume needs improvement\n",
    "  > * Low Score (<50%) -> Resume is not a good match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1616705c-8779-4928-b71c-b56b614e1787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import nltk\n",
    "import re\n",
    "import docx\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer,util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0b8b819-cc89-422e-819a-dd9a97a676cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/khushimadan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfe9b3a7-9294-424f-afde-8ec9286fc64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/khushimadan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce3b1e4a-f2d9-42b3-8168-4d0760ffc04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "747de856-2835-498f-9fe6-a60e3a6f942b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " \"he's\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9a0634-2deb-4af3-9946-2a9819616d31",
   "metadata": {},
   "source": [
    "## Data Extraction and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af940938-17f7-4f2a-8990-419ad23f9554",
   "metadata": {},
   "source": [
    "#### Extracting text from resume\n",
    "> Supports both pdf and docx formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57d30acb-f2f2-40f5-9153-9cfffd943c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_resume_text(file_path):\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            text = \"\\n\".join([page.extract_text() or \"\" for page in pdf.pages])\n",
    "    elif file_path.endswith(\".docx\"):\n",
    "        doc = docx.Document(file_path)\n",
    "        text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfddcb1-c5ae-4a02-ac76-92fd820f2f49",
   "metadata": {},
   "source": [
    "#### Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66ae59b6-0c47-46f5-9c12-66892261d44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Khushi Madan\n",
      "Delhi, India | P: +91 8375876890 | khushimadan11@gmail.com | LinkedIn | GitHub | LeetCode\n",
      "EDUCATION\n",
      "MANIPAL UNIVERSITY JAIPUR Jaipur, Rajasthan\n",
      "Bachelor of Technology (Hons) Computer Science and Engineering with specialization in September 2022 - May 2026\n",
      "Artificial Intelligence and Machine Learning\n",
      "Cumulative GPA: 8.97/10.0; Dean’s List 2023-2024\n",
      "Technical Lead at Google Developer Groups on Campus\n",
      "VENKATESHWAR INTERNATIONAL SCHOOL Dwarka, Delhi\n",
      "High School Diploma in Physics, Chemistry, Maths with Computer Science (CBSE) April 2008 - June 2022\n",
      "10th - 92.6% and 12th - 86.6%\n",
      "SKILLS\n",
      "Technical Skills - C, C++, Python, Machine Learning, Data Analysis, Flutter, HTML, CSS, Linux, AutoCAD, SQL, JavaScript,\n",
      "Bootstrap, Power BI, Data Science, Data Visualization, Artificial Intelligence, Figma, Excel, Scikit Learn, Flask and Firebase\n",
      "Relevant Coursework - Operating Systems, Principles of Artificial Intelligence, Software Engineering and Project Management,\n",
      "Computer Networks, Data Structures and Algorithms, Object Oriented Programming, and Database Management Systems.\n",
      "WORK EXPERIENCE\n",
      "ARCADIS Gurugram, Haryana\n",
      "Data Analyst Intern July 2024 - September 2024\n",
      "● Designed and implemented interactive dashboards in Microsoft Power BI, integrating Python libraries like Seaborn,\n",
      "Matplotlib and Pandas to improve data visualization and data analysis processes, resulting in 30% increase in efficiency.\n",
      "● Developed Python scripts to automate tasks for the Business Analytics Team reducing manual workload by 40% and saving\n",
      "over 15 hours of work per week.\n",
      "PROJECTS\n",
      "ZERO TRUST PASSWORD\n",
      "● Collaborated with a team to develop a Full Stack Web Application and focused on backend development using Python,\n",
      "MySQL and Flask for backend, HTML and CSS for frontend.\n",
      "● It identifies weak passwords containing the personal information of users. Implemented a password recommender system\n",
      "and strength checker, increasing password strength by 25% and reducing vulnerability by 20%.\n",
      "● Engineered an OTP verification system and estimated time to hack, boosting user security and reducing brute-force attack\n",
      "risk by 30%.\n",
      "FIX MY CITY (In Progress)\n",
      "● Building FixMyCity, a Flutter-based civic issue-reporting app for Android and IOS with real-time tracking, leveraging Firebase for\n",
      "storage and analytics and PyTorch for AI-powered workforce allocation, streamlining issue resolution by 30-40%.\n",
      "HEART DISEASE PREDICTION\n",
      "● Developed a Heart Disease Prediction model using Logistic Regression, achieving ~90% accuracy on the UCI Heart Disease\n",
      "dataset.\n",
      "BLOG WEBSITE\n",
      "● Designed a responsive Blog Website using HTML,CSS and JavaScript highlighting front-end development expertise.\n",
      "ADDITIONAL\n",
      "Achievements:\n",
      "● Received the Dean’s Excellence in Academics award in 3rd and 4th semesters consecutively.\n",
      "● Chosen by Stanford University for their Code in Place program, one of 10k students selected from over 70k applications.\n",
      "● Selected among 100 students from 2nd and 3rd years to participate in the Hack to Hire Hackathon organized by Dell\n",
      "Technologies.\n",
      "Certifications:\n",
      "● Supervised Machine Learning course by DeepLearning.AI\n",
      "● Python for Data Science, AI & Development course by IBM\n",
      "● Design and Analysis of Algorithms and Data Structures courses by Swayam NPTEL\n",
      "● Database Foundations and Database Programming with SQL courses by Oracle Academy\n"
     ]
    }
   ],
   "source": [
    "resume_text = extract_resume_text(\"Khushi_Madan_Resume.pdf\")\n",
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d8f55f4-faa3-48bc-9535-54df4271069b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Khushi Madan\n",
      "Delhi, India | P: +91 8375876890 | khushimadan11@gmail.com | LinkedIn | GitHub | LeetCode\n",
      "EDUCATION\n",
      "MANIPAL UNIVERSITY JAIPUR\tJaipur, Rajasthan\n",
      "Bachelor of Technology (Hons) Computer Science and Engineering with specialization in\tSeptember 2022 - May 2026 Artificial Intelligence and Machine Learning\n",
      "Cumulative GPA: 8.97/10.0; Dean’s List 2023-2024\n",
      "Technical Lead at Google Developer Groups on Campus\n",
      "VENKATESHWAR INTERNATIONAL SCHOOL\tDwarka, Delhi\n",
      "High School Diploma in Physics, Chemistry, Maths with Computer Science (CBSE)\tApril 2008 - June 2022 10th - 92.6% and 12th - 86.6%\n",
      "SKILLS\n",
      "Technical Skills - C, C++, Python, Machine Learning, Data Analysis, Flutter, HTML, CSS, Linux, AutoCAD, SQL, JavaScript, Bootstrap, Power BI, Data Science, Data Visualization, Artificial Intelligence, Figma, Excel, Scikit Learn, Flask and Firebase Relevant Coursework - Operating Systems, Principles of Artificial Intelligence, Software Engineering and Project Management, Computer Networks, Data Structures and Algorithms, Object Oriented Programming, and Database Management Systems.\n",
      "WORK EXPERIENCE\n",
      "ARCADIS\tGurugram, Haryana\n",
      "Data Analyst Intern\tJuly 2024 - September 2024\n",
      "Designed and implemented interactive dashboards in Microsoft Power BI, integrating Python libraries like Seaborn, Matplotlib and Pandas to improve data visualization and data analysis processes, resulting in 30% increase in efficiency.\n",
      "Developed Python scripts to automate tasks for the Business Analytics Team reducing manual workload by 40% and saving over 15 hours of work per week.\n",
      "PROJECTS\n",
      "ZERO TRUST PASSWORD\n",
      "Collaborated with a team to develop a Full Stack Web Application and focused on backend development using Python, MySQL and Flask for backend, HTML and CSS for frontend.\n",
      "It identifies weak passwords containing the personal information of users. Implemented a password recommender system and strength checker, increasing password strength by 25% and reducing vulnerability by 20%.\n",
      "Engineered an OTP verification system and estimated time to hack, boosting user security and reducing brute-force attack risk by 30%.\n",
      "FIX MY CITY (In Progress)\n",
      "Building FixMyCity, a Flutter-based civic issue-reporting app for Android and IOS with real-time tracking, leveraging Firebase for storage and analytics and PyTorch for AI-powered workforce allocation, streamlining issue resolution by 30-40%.\n",
      "HEART DISEASE PREDICTION\n",
      "Developed a Heart Disease Prediction model using Logistic Regression, achieving ~90% accuracy on the UCI Heart Disease dataset.\n",
      "BLOG WEBSITE\n",
      "Designed a responsive Blog Website using HTML,CSS and JavaScript highlighting front-end development expertise.\n",
      "ADDITIONAL\n",
      "Achievements:\n",
      "Received the Dean’s Excellence in Academics award in 3rd and 4th semesters consecutively.\n",
      "Chosen by Stanford University for their Code in Place program, one of 10k students selected from over 70k applications.\n",
      "Selected among 100 students from 2nd and 3rd years to participate in the Hack to Hire Hackathon organized by Dell Technologies.\n",
      "Certifications:\n",
      "Supervised Machine Learning course by DeepLearning.AI\n",
      "Python for Data Science, AI & Development course by IBM\n",
      "Design and Analysis of Algorithms and Data Structures courses by Swayam NPTEL\n",
      "Database Foundations and Database Programming with SQL courses by Oracle Academy\n"
     ]
    }
   ],
   "source": [
    "doc_text = extract_resume_text(\"Khushi_Madan_Resume.docx\")\n",
    "print(doc_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10646757-c225-46cf-b514-c8791d5650ea",
   "metadata": {},
   "source": [
    "#### Preprocessing Text\n",
    "> * Cleaning Text\n",
    "> * Tokenization\n",
    "> * Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38a7f7fb-21de-465c-8b18-c9802ef6ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text) #removing special characters\n",
    "    tokens = word_tokenize(text) #Tokenization\n",
    "    tokens = [word for word in tokens if word not in stop_words] #removing stopwords from our corpus\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f205b98-5d89-4a34-b15a-a73cccabfb3a",
   "metadata": {},
   "source": [
    "#### Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cce8d779-7cf3-452b-9d18-40bc75b1e824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "khushi madan delhi india p 91 8375876890 khushimadan11gmailcom linkedin github leetcode education manipal university jaipur jaipur rajasthan bachelor technology hons computer science engineering specialization september 2022 may 2026 artificial intelligence machine learning cumulative gpa 897100 deans list 20232024 technical lead google developer groups campus venkateshwar international school dwarka delhi high school diploma physics chemistry maths computer science cbse april 2008 june 2022 10th 926 12th 866 skills technical skills c c python machine learning data analysis flutter html css linux autocad sql javascript bootstrap power bi data science data visualization artificial intelligence figma excel scikit learn flask firebase relevant coursework operating systems principles artificial intelligence software engineering project management computer networks data structures algorithms object oriented programming database management systems work experience arcadis gurugram haryana data analyst intern july 2024 september 2024 designed implemented interactive dashboards microsoft power bi integrating python libraries like seaborn matplotlib pandas improve data visualization data analysis processes resulting 30 increase efficiency developed python scripts automate tasks business analytics team reducing manual workload 40 saving 15 hours work per week projects zero trust password collaborated team develop full stack web application focused backend development using python mysql flask backend html css frontend identifies weak passwords containing personal information users implemented password recommender system strength checker increasing password strength 25 reducing vulnerability 20 engineered otp verification system estimated time hack boosting user security reducing bruteforce attack risk 30 fix city progress building fixmycity flutterbased civic issuereporting app android ios realtime tracking leveraging firebase storage analytics pytorch aipowered workforce allocation streamlining issue resolution 3040 heart disease prediction developed heart disease prediction model using logistic regression achieving 90 accuracy uci heart disease dataset blog website designed responsive blog website using htmlcss javascript highlighting frontend development expertise additional achievements received deans excellence academics award 3rd 4th semesters consecutively chosen stanford university code place program one 10k students selected 70k applications selected among 100 students 2nd 3rd years participate hack hire hackathon organized dell technologies certifications supervised machine learning course deeplearningai python data science ai development course ibm design analysis algorithms data structures courses swayam nptel database foundations database programming sql courses oracle academy\n"
     ]
    }
   ],
   "source": [
    "clean_resume_text = preprocess_text(resume_text)\n",
    "print(clean_resume_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870f4c4f-61b2-42a0-90c8-dd95d26311ff",
   "metadata": {},
   "source": [
    "## Converting Resume and Job Description to Vectors!\n",
    "\n",
    "> Converting text into numerical form using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e80f226-935b-46f9-bafb-202675078116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_resumes(resumes, job_description):\n",
    "    all_texts = resumes + [job_description]\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
    "\n",
    "    job_vec = tfidf_matrix[-1] #JD Vector\n",
    "    resume_vecs = tfidf_matrix[:-1] #Resume vectors\n",
    "\n",
    "    similarity_scores = cosine_similarity(resume_vecs, job_vec)\n",
    "    return similarity_scores.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4ccc591d-ec3f-4810-bdf9-8eb3e89ae35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = [clean_resume_text]\n",
    "job_description = \"\"\"Job Title: Data Analyst Intern  \n",
    "\n",
    "Location: Remote / XYZCompany  \n",
    "\n",
    "Duration: 2 months \n",
    "\n",
    "About the Role:  \n",
    "We are looking for a Data Analyst Intern to support our project by analyzing, cleaning, and visualizing business and employee task data. This role involves working with large datasets, extracting insights, and creating reports and dashboards to drive decision-making.  \n",
    "\n",
    "Key Responsibilities:  \n",
    "- Collect, clean, and preprocess data from multiple sources, including Excel and databases.  \n",
    "- Perform data analysis to identify trends, patterns, and insights.  \n",
    "- Develop visualizations and interactive dashboards using Power BI and Python (Pandas, Matplotlib, Seaborn).  \n",
    "- Work with stakeholders to understand data requirements and optimize reporting.  \n",
    "- Assist in automating data extraction, transformation, and consolidation processes.  \n",
    "- Ensure data accuracy and integrity across all reports and visualizations.  \n",
    "\n",
    "Required Skills:  \n",
    "- Strong analytical skills with experience in Excel, SQL, and Python (Pandas, Numpy, Matplotlib).  \n",
    "- Hands-on experience with Power BI for data visualization.  \n",
    "- Understanding of data structures, cleaning, and transformation techniques.  \n",
    "- Ability to work independently and manage multiple tasks efficiently.  \n",
    "- Strong problem-solving skills and attention to detail.  \n",
    "\n",
    "Preferred Qualifications:  \n",
    "- Experience with business analytics, reporting, and performance tracking.  \n",
    "- Familiarity with data extraction from multiple Excel sheets and consolidation techniques.  \n",
    "- Basic understanding of machine learning concepts is a plus.  \n",
    "\n",
    "What You’ll Gain:  \n",
    "- Hands-on experience working with real-world business and employee task data.  \n",
    "- Exposure to industry-standard tools and technologies.  \n",
    "- Opportunity to contribute to decision-making processes through data-driven insights.  \n",
    "- Mentorship and guidance to enhance your analytical and technical skills.  \n",
    "\n",
    "How to Apply:  \n",
    "Send your resume and a brief cover letter to xyzcompany@gmail.com.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5e079549-674d-479e-a5de-28c8a2fcc68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'job title data analyst intern location remote xyzcompany duration 2 months role looking data analyst intern support project analyzing cleaning visualizing business employee task data role involves working large datasets extracting insights creating reports dashboards drive decisionmaking key responsibilities collect clean preprocess data multiple sources including excel databases perform data analysis identify trends patterns insights develop visualizations interactive dashboards using power bi python pandas matplotlib seaborn work stakeholders understand data requirements optimize reporting assist automating data extraction transformation consolidation processes ensure data accuracy integrity across reports visualizations required skills strong analytical skills experience excel sql python pandas numpy matplotlib handson experience power bi data visualization understanding data structures cleaning transformation techniques ability work independently manage multiple tasks efficiently strong problemsolving skills attention detail preferred qualifications experience business analytics reporting performance tracking familiarity data extraction multiple excel sheets consolidation techniques basic understanding machine learning concepts plus youll gain handson experience working realworld business employee task data exposure industrystandard tools technologies opportunity contribute decisionmaking processes datadriven insights mentorship guidance enhance analytical technical skills apply send resume brief cover letter xyzcompanygmailcom'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_description = preprocess_text(job_description)\n",
    "job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "93011b1c-0b1f-4ec6-b154-64a4388a75de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24759701]\n"
     ]
    }
   ],
   "source": [
    "scores = rank_resumes(resumes, job_description)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6325e08e-71a2-44fd-90a6-88c20e4fd12c",
   "metadata": {},
   "source": [
    "#### !!! Low Score of TF-IDF is because it does not understand meaning and only focuses on word frequency. Even if skills match TF-IDF would not recognize synonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d5671d-d3fd-46ff-b2a4-4c02c27a907b",
   "metadata": {},
   "source": [
    "## Improve matching with BERT\n",
    "> Instead of TF-IDF, BERT embeddings can be used for better context understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2f6846ff-a872-45b6-bce8-0a8f94c3c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_resumes_with_bert(resumes, job_description):\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    resume_embeddings = model.encode(resumes,convert_to_tensor=True)\n",
    "    jd_embedding = model.encode(job_description,convert_to_tensor=True)\n",
    "\n",
    "    similarity_scores = util.pytorch_cos_sim(resume_embeddings,jd_embedding)\n",
    "    return similarity_scores.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "64dedd65-0260-4b0a-8273-4453a9e7e4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6897550225257874]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_bert = rank_resumes_with_bert([clean_resume_text],job_description)\n",
    "scores_bert"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
